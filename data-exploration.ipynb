{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf31c2bb",
   "metadata": {},
   "source": [
    "# Full pipeline for Text Data Exploration\n",
    "\n",
    "As a data scientist specializing in Natural Language Processing (NLP), a thorough data exploration phase is crucial for understanding the text data, identifying patterns, and informing subsequent preprocessing and modeling steps. Here's a comprehensive pipeline with common tasks, tips, code, libraries, and useful charts, presented step-by-step in Python. The data used by this guide can be downloaded from https://zenodo.org/records/10157504."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e17c875",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Initial Inspection\n",
    "\n",
    "**Common Task**: Load your text data and get a first glance at its structure and content.\n",
    "\n",
    "**Tips**:\n",
    "- Start with a sample if your dataset is massive.\n",
    "- Understand the format: Is it a CSV, JSON, database, etc.?\n",
    "- Check for missing values immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9a3b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5315ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_input = '*.*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a312d02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AllProductReviews.csv', 'data-exploration.ipynb', 'README.md']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Understanding the type of file, looking for the extension file\n",
    "file_list = glob.glob(file_input)\n",
    "len(file_list)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c53753ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews =pd.read_csv(file_list[0], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f18ecb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewTitle</th>\n",
       "      <th>ReviewBody</th>\n",
       "      <th>ReviewStar</th>\n",
       "      <th>Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honest review of an edm music lover\\n</td>\n",
       "      <td>No doubt it has a great bass and to a great ex...</td>\n",
       "      <td>3</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unreliable earphones with high cost\\n</td>\n",
       "      <td>This  earphones are unreliable, i bought it be...</td>\n",
       "      <td>1</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really good and durable.\\n</td>\n",
       "      <td>i bought itfor 999,I purchased it second time,...</td>\n",
       "      <td>4</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stopped working in just 14 days\\n</td>\n",
       "      <td>Its sound quality is adorable. overall it was ...</td>\n",
       "      <td>1</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just Awesome Wireless Headphone under 1000...ðŸ˜‰\\n</td>\n",
       "      <td>Its Awesome... Good sound quality &amp; 8-9 hrs ba...</td>\n",
       "      <td>5</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ReviewTitle  \\\n",
       "0             Honest review of an edm music lover\\n   \n",
       "1             Unreliable earphones with high cost\\n   \n",
       "2                        Really good and durable.\\n   \n",
       "3                 stopped working in just 14 days\\n   \n",
       "4  Just Awesome Wireless Headphone under 1000...ðŸ˜‰\\n   \n",
       "\n",
       "                                          ReviewBody  ReviewStar  \\\n",
       "0  No doubt it has a great bass and to a great ex...           3   \n",
       "1  This  earphones are unreliable, i bought it be...           1   \n",
       "2  i bought itfor 999,I purchased it second time,...           4   \n",
       "3  Its sound quality is adorable. overall it was ...           1   \n",
       "4  Its Awesome... Good sound quality & 8-9 hrs ba...           5   \n",
       "\n",
       "            Product  \n",
       "0  boAt Rockerz 255  \n",
       "1  boAt Rockerz 255  \n",
       "2  boAt Rockerz 255  \n",
       "3  boAt Rockerz 255  \n",
       "4  boAt Rockerz 255  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a31082e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14337 entries, 0 to 14336\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ReviewTitle  14337 non-null  object\n",
      " 1   ReviewBody   14337 non-null  object\n",
      " 2   ReviewStar   14337 non-null  int64 \n",
      " 3   Product      14337 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 448.2+ KB\n"
     ]
    }
   ],
   "source": [
    "reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2518f7",
   "metadata": {},
   "source": [
    "There isn't null. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490eaa28",
   "metadata": {},
   "source": [
    "# 2. Basic Text Statistics\n",
    "\n",
    "**Common Tasks**: Calculate fundamental statistics about your text data to understand its overall characteristics.\n",
    "\n",
    "**Tips**:\n",
    "- Character count can indicate brevity or verbosity.\n",
    "- Word count and sentence count provide insights into text length and complexity.\n",
    "- Average word length can hint at the formality or simplicity of the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06d49a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the data, replace \\n with \"\"\n",
    "reviews['ReviewTitle'] = reviews['ReviewTitle'].str.replace('\\n', '', regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e715ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['char_count_Title'] = reviews['ReviewTitle'].str.len()\n",
    "reviews['char_count_Body'] = reviews['ReviewBody'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b375ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['word_count_Body'] = reviews['ReviewBody'].str.split().str.len()\n",
    "reviews['sentence_count_Body'] = reviews['ReviewBody'].str.split('.').str.len()\n",
    "reviews['word_len_Body'] = reviews['ReviewBody'].str.split().apply(lambda word_list: [len(word) for word in word_list])\n",
    "reviews['average_word_len'] = reviews['word_len_Body'].apply(lambda counts: sum(counts)/len(counts) if counts else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e69cf780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewStar</th>\n",
       "      <th>char_count_Title</th>\n",
       "      <th>char_count_Body</th>\n",
       "      <th>word_count_Body</th>\n",
       "      <th>sentence_count_Body</th>\n",
       "      <th>average_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14337.000000</td>\n",
       "      <td>14337.000000</td>\n",
       "      <td>14337.000000</td>\n",
       "      <td>14337.000000</td>\n",
       "      <td>14337.000000</td>\n",
       "      <td>14337.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.675874</td>\n",
       "      <td>21.545791</td>\n",
       "      <td>126.584362</td>\n",
       "      <td>22.320709</td>\n",
       "      <td>3.666039</td>\n",
       "      <td>4.836041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.503409</td>\n",
       "      <td>16.443729</td>\n",
       "      <td>154.807798</td>\n",
       "      <td>27.702611</td>\n",
       "      <td>3.910061</td>\n",
       "      <td>1.010389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>5046.000000</td>\n",
       "      <td>864.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ReviewStar  char_count_Title  char_count_Body  word_count_Body  \\\n",
       "count  14337.000000      14337.000000     14337.000000     14337.000000   \n",
       "mean       3.675874         21.545791       126.584362        22.320709   \n",
       "std        1.503409         16.443729       154.807798        27.702611   \n",
       "min        1.000000          1.000000         1.000000         0.000000   \n",
       "25%        3.000000         10.000000        36.000000         6.000000   \n",
       "50%        4.000000         16.000000        88.000000        15.000000   \n",
       "75%        5.000000         28.000000       160.000000        28.000000   \n",
       "max        5.000000        128.000000      5046.000000       864.000000   \n",
       "\n",
       "       sentence_count_Body  average_word_len  \n",
       "count         14337.000000      14337.000000  \n",
       "mean              3.666039          4.836041  \n",
       "std               3.910061          1.010389  \n",
       "min               1.000000          0.000000  \n",
       "25%               1.000000          4.240000  \n",
       "50%               2.000000          4.666667  \n",
       "75%               5.000000          5.222222  \n",
       "max              65.000000         31.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4460b6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No doubt it has a great bass and to a great extent noise cancellation and decent sound clarity and mindblowing battery but the following dissapointed me though i tried a lot to adjust.1.Bluetooth range not more than 10m2. Pain in ear due the conical buds(can be removed)3. Wires are a bit long which makes it odd in front.4. No pouch provided.5. Worst part is very low quality and distoring mic. Other person keeps complaining about my voice.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()\n",
    "reviews['ReviewBody'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c630d27",
   "metadata": {},
   "source": [
    "# 3. Text Preprocessing (for Exploration)\n",
    "\n",
    "**Common Tasks**: Clean and normalize text to prepare it for frequency analysis and other exploratory tasks. This is a lighter preprocessing step compared to what you might do for modeling.\n",
    "\n",
    "**Tips**:\n",
    "- Lowercasing prevents treating \"The\" and \"the\" as different words.\n",
    "- Punctuation removal reduces noise.\n",
    "- Stopword removal focuses on meaningful content words.\n",
    "- Stemming/Lemmatization reduces words to their root forms, consolidating variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8615fc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d7c3128",
   "metadata": {},
   "source": [
    "# 4. Vocabulary Analysis\n",
    "\n",
    "**Common Tasks**: Understand the unique words, their frequencies, and patterns.\n",
    "\n",
    "**Tips**:\n",
    "\n",
    "- Word clouds provide a quick visual summary of frequent terms.\n",
    "- Bar charts of top N words show exact frequencies.\n",
    "- Analyzing n-grams (bigrams, trigrams) reveals common phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b608c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87ed15d4",
   "metadata": {},
   "source": [
    "# 5. Part-of-Speech (POS) Tagging\n",
    "\n",
    "**Common Task**: Analyze the distribution of grammatical categories (nouns, verbs, adjectives, etc.) in your text.\n",
    "\n",
    "**Tips**:\n",
    "\n",
    "- Provides insights into the linguistic structure of your corpus.\n",
    "- Can highlight if your text is descriptive (many adjectives), action-oriented (many verbs), or topic-focused (many nouns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c67be66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57be9595",
   "metadata": {},
   "source": [
    "# 6. Named Entity Recognition (NER)\n",
    "\n",
    "**Common Task**: Identify and categorize named entities (people, organizations, locations, dates, etc.) in your text.\n",
    "\n",
    "**Tips**:\n",
    "\n",
    "- Reveals key subjects and concepts in your data.\n",
    "- Useful for extracting structured information from unstructured text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5df89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bad472d2",
   "metadata": {},
   "source": [
    "# 7. Sentiment Analysis (if applicable)\n",
    "\n",
    "**Common Task**: Determine the emotional tone (positive, negative, neutral) of your text data.\n",
    "\n",
    "**Tips**:\n",
    "\n",
    "- Provides a high-level understanding of the sentiment distribution.\n",
    "- Can be done with simple lexicon-based models or more complex pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa134e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdfbb4d3",
   "metadata": {},
   "source": [
    "# 8. Topic Modeling (High-level exploration)\n",
    "\n",
    "**Common Task**: Discover abstract \"topics\" that occur in a collection of documents.\n",
    "\n",
    "**Tips**:\n",
    "\n",
    "- LDA (Latent Dirichlet Allocation) is a common algorithm.\n",
    "- Requires a document-term matrix.\n",
    "- Provides a sense of the main themes present in your corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e200749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
